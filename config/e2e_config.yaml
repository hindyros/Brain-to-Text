# Configuration for end-to-end models (direct neural -> text)

# Model configuration
model:
  n_channels: 512
  d_model: 512
  n_encoder_layers: 8
  n_decoder_layers: 6
  n_heads: 8
  dropout: 0.1

# Training configuration
batch_size: 16
num_epochs: 50
learning_rate: 5e-4
weight_decay: 0.01
grad_clip: 1.0
use_augmentation: true
use_amp: true  # Mixed precision training

# Data configuration
num_workers: 4
pin_memory: true

# Checkpoint configuration
checkpoint_dir: checkpoints/e2e

# Augmentation configuration
augmentation:
  temporal_mask_prob: 0.3
  temporal_mask_percentage: 0.1
  electrode_dropout_prob: 0.2
  electrode_dropout_rate: 0.1
  gaussian_noise_prob: 0.25
  gaussian_noise_std: 0.05

# Inference configuration
inference:
  max_len: 200
  temperature: 1.0
  beam_width: 5

